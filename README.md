# Модель релевантной выдачи

## Модели
Сохраненные обученные модели лежат в [models](/models)
- *RandomForestClassifier*
- *CatboostRanker*
- *LgbmRanker*

## Перформанс на тесте

|                        |   NDCG(0) |   NDCG(1) |   NDCG(ignore) |   NDCG(all) |
|:-----------------------|----------:|----------:|---------------:|------------:|
| Constant_classifier    |  0.10011  |  0.85011  |       0.400439 |    0.365642 |
| CatBoostRanker         |  0.139868 |  0.889868 |       0.559473 |    0.448856 |
| LGBMRanker             |  0.112007 |  0.862007 |       0.448028 |    0.491057 |
| RandomForestClassifier |  0.10011  |  0.85011  |       0.400439 |    0.364892 |

## Примичание 1
Разные NDCG метрики, потому что первые три для ранжирования внутри группы и по разному решают проблему IDCG = 0. Последний - качество ранжирования по всему датасету

## Примичание 2
Не смотря на то, что на валидации лучше справлялся обычный классификатор, на тестовом наборе он ведет себя примерно так же, как константный классификатор. На тесте лучше всего себя показали ранкеры, выбирать конкретный не буду, так как зависит от задачи: если надо предсказывать релевантность из всех запросов - то *LGBMRanker*, если ранжировать внутри группы - *CatBoostRanker*.

## Обучение
Ноутбуки с обучением находятся в [expirements](/expirements)